/home/stu024/CS_205/KNN.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.
  small_data_19 = pd.read_csv('/home/stu024/CS_205/CS205_small_Data__19.txt', sep='  ', header=None)
/home/stu024/CS_205/KNN.py:13: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.
  large_data_6 = pd.read_csv('/home/stu024/CS_205/CS205_large_Data__6.txt', sep='  ', header=None)
/home/stu024/CS_205/KNN.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.
  small_data_21 = pd.read_csv('/home/stu024/CS_205/CS205_small_Data__21.txt', sep='  ', header=None)
/home/stu024/CS_205/KNN.py:24: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.
  large_data_13 = pd.read_csv('/home/stu024/CS_205/CS205_large_Data__13.txt', sep='  ', header=None)
Welcome to KNN Feature Selection Algorithm!

Please select the file you would like to test: 
1. Sample Small 19
2. Assigned Small 21
3. Sample Large 6
4. Assigned Larg 13e

Your selection: Please select the algorithm you would like to run: 

1. Forward Selection
2. Backward Elimination
3. Both

Your selection: This dataset has 12 features (not including the class attribute), with 500 instances.

Running KNN with all 12 Ã¥features, using "leave-one-out" evaluation, I get an accuracy of 0.75%

Beginning search.

Starting with Forward Selection.

	Using feature(s) {1} accuracy is 0.672%
	Using feature(s) {2} accuracy is 0.636%
	Using feature(s) {3} accuracy is 0.65%
	Using feature(s) {4} accuracy is 0.656%
	Using feature(s) {5} accuracy is 0.642%
	Using feature(s) {6} accuracy is 0.84%
	Using feature(s) {7} accuracy is 0.654%
	Using feature(s) {8} accuracy is 0.668%
	Using feature(s) {9} accuracy is 0.742%
	Using feature(s) {10} accuracy is 0.656%
	Using feature(s) {11} accuracy is 0.658%
	Using feature(s) {12} accuracy is 0.664%

Feature set {6} was best, accuracy is 0.84%

	Using feature(s) {6,1} accuracy is 0.828%
	Using feature(s) {6,2} accuracy is 0.822%
	Using feature(s) {6,3} accuracy is 0.816%
	Using feature(s) {6,4} accuracy is 0.822%
	Using feature(s) {6,5} accuracy is 0.836%
	Using feature(s) {6,7} accuracy is 0.808%
	Using feature(s) {6,8} accuracy is 0.808%
	Using feature(s) {6,9} accuracy is 0.95%
	Using feature(s) {6,10} accuracy is 0.812%
	Using feature(s) {6,11} accuracy is 0.858%
	Using feature(s) {6,12} accuracy is 0.814%

Feature set {6,9} was best, accuracy is 0.95%

	Using feature(s) {6,9,1} accuracy is 0.914%
	Using feature(s) {6,9,2} accuracy is 0.924%
	Using feature(s) {6,9,3} accuracy is 0.918%
	Using feature(s) {6,9,4} accuracy is 0.928%
	Using feature(s) {6,9,5} accuracy is 0.926%
	Using feature(s) {6,9,7} accuracy is 0.928%
	Using feature(s) {6,9,8} accuracy is 0.928%
	Using feature(s) {6,9,10} accuracy is 0.922%
	Using feature(s) {6,9,11} accuracy is 0.946%
	Using feature(s) {6,9,12} accuracy is 0.916%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {6,9,11} was best, accuracy is 0.946%

	Using feature(s) {6,9,11,1} accuracy is 0.876%
	Using feature(s) {6,9,11,2} accuracy is 0.912%
	Using feature(s) {6,9,11,3} accuracy is 0.888%
	Using feature(s) {6,9,11,4} accuracy is 0.896%
	Using feature(s) {6,9,11,5} accuracy is 0.91%
	Using feature(s) {6,9,11,7} accuracy is 0.884%
	Using feature(s) {6,9,11,8} accuracy is 0.908%
	Using feature(s) {6,9,11,10} accuracy is 0.92%
	Using feature(s) {6,9,11,12} accuracy is 0.874%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {6,9,11,10} was best, accuracy is 0.92%

	Using feature(s) {6,9,11,10,1} accuracy is 0.86%
	Using feature(s) {6,9,11,10,2} accuracy is 0.862%
	Using feature(s) {6,9,11,10,3} accuracy is 0.86%
	Using feature(s) {6,9,11,10,4} accuracy is 0.848%
	Using feature(s) {6,9,11,10,5} accuracy is 0.848%
	Using feature(s) {6,9,11,10,7} accuracy is 0.834%
	Using feature(s) {6,9,11,10,8} accuracy is 0.844%
	Using feature(s) {6,9,11,10,12} accuracy is 0.822%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {6,9,11,10,2} was best, accuracy is 0.862%

	Using feature(s) {6,9,11,10,2,1} accuracy is 0.854%
	Using feature(s) {6,9,11,10,2,3} accuracy is 0.824%
	Using feature(s) {6,9,11,10,2,4} accuracy is 0.804%
	Using feature(s) {6,9,11,10,2,5} accuracy is 0.826%
	Using feature(s) {6,9,11,10,2,7} accuracy is 0.798%
	Using feature(s) {6,9,11,10,2,8} accuracy is 0.812%
	Using feature(s) {6,9,11,10,2,12} accuracy is 0.802%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {6,9,11,10,2,1} was best, accuracy is 0.854%

	Using feature(s) {6,9,11,10,2,1,3} accuracy is 0.798%
	Using feature(s) {6,9,11,10,2,1,4} accuracy is 0.784%
	Using feature(s) {6,9,11,10,2,1,5} accuracy is 0.796%
	Using feature(s) {6,9,11,10,2,1,7} accuracy is 0.804%
	Using feature(s) {6,9,11,10,2,1,8} accuracy is 0.81%
	Using feature(s) {6,9,11,10,2,1,12} accuracy is 0.802%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {6,9,11,10,2,1,8} was best, accuracy is 0.81%

	Using feature(s) {6,9,11,10,2,1,8,3} accuracy is 0.778%
	Using feature(s) {6,9,11,10,2,1,8,4} accuracy is 0.778%
	Using feature(s) {6,9,11,10,2,1,8,5} accuracy is 0.78%
	Using feature(s) {6,9,11,10,2,1,8,7} accuracy is 0.764%
	Using feature(s) {6,9,11,10,2,1,8,12} accuracy is 0.78%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {6,9,11,10,2,1,8,12} was best, accuracy is 0.78%

	Using feature(s) {6,9,11,10,2,1,8,12,3} accuracy is 0.744%
	Using feature(s) {6,9,11,10,2,1,8,12,4} accuracy is 0.742%
	Using feature(s) {6,9,11,10,2,1,8,12,5} accuracy is 0.772%
	Using feature(s) {6,9,11,10,2,1,8,12,7} accuracy is 0.722%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {6,9,11,10,2,1,8,12,5} was best, accuracy is 0.772%

	Using feature(s) {6,9,11,10,2,1,8,12,5,3} accuracy is 0.74%
	Using feature(s) {6,9,11,10,2,1,8,12,5,4} accuracy is 0.736%
	Using feature(s) {6,9,11,10,2,1,8,12,5,7} accuracy is 0.744%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {6,9,11,10,2,1,8,12,5,7} was best, accuracy is 0.744%

	Using feature(s) {6,9,11,10,2,1,8,12,5,7,3} accuracy is 0.752%
	Using feature(s) {6,9,11,10,2,1,8,12,5,7,4} accuracy is 0.73%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {6,9,11,10,2,1,8,12,5,7,3} was best, accuracy is 0.752%

	Using feature(s) {6,9,11,10,2,1,8,12,5,7,3,4} accuracy is 0.75%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {6,9,11,10,2,1,8,12,5,7,3,4} was best, accuracy is 0.75%

Finished search!!! The best feature subset is {6,9}, which has an accuracy of 0.95%
Elapsed (after compilation) = 80.37786626815796
Starting Backward Elimination.

	Removing feature(s) {1} accuracy is 0.734%
	Removing feature(s) {2} accuracy is 0.708%
	Removing feature(s) {3} accuracy is 0.73%
	Removing feature(s) {4} accuracy is 0.752%
	Removing feature(s) {5} accuracy is 0.726%
	Removing feature(s) {6} accuracy is 0.672%
	Removing feature(s) {7} accuracy is 0.714%
	Removing feature(s) {8} accuracy is 0.734%
	Removing feature(s) {9} accuracy is 0.702%
	Removing feature(s) {10} accuracy is 0.736%
	Removing feature(s) {11} accuracy is 0.758%
	Removing feature(s) {12} accuracy is 0.75%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {11} was best, accuracy is 0.758%

	Removing feature(s) {11,1} accuracy is 0.76%
	Removing feature(s) {11,2} accuracy is 0.734%
	Removing feature(s) {11,3} accuracy is 0.766%
	Removing feature(s) {11,4} accuracy is 0.774%
	Removing feature(s) {11,5} accuracy is 0.784%
	Removing feature(s) {11,6} accuracy is 0.7%
	Removing feature(s) {11,7} accuracy is 0.746%
	Removing feature(s) {11,8} accuracy is 0.768%
	Removing feature(s) {11,9} accuracy is 0.71%
	Removing feature(s) {11,10} accuracy is 0.762%
	Removing feature(s) {11,12} accuracy is 0.77%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {11,5} was best, accuracy is 0.784%

	Removing feature(s) {11,5,1} accuracy is 0.744%
	Removing feature(s) {11,5,2} accuracy is 0.77%
	Removing feature(s) {11,5,3} accuracy is 0.778%
	Removing feature(s) {11,5,4} accuracy is 0.784%
	Removing feature(s) {11,5,6} accuracy is 0.698%
	Removing feature(s) {11,5,7} accuracy is 0.76%
	Removing feature(s) {11,5,8} accuracy is 0.758%
	Removing feature(s) {11,5,9} accuracy is 0.722%
	Removing feature(s) {11,5,10} accuracy is 0.762%
	Removing feature(s) {11,5,12} accuracy is 0.784%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {11,5,12} was best, accuracy is 0.784%

	Removing feature(s) {11,5,12,1} accuracy is 0.774%
	Removing feature(s) {11,5,12,2} accuracy is 0.798%
	Removing feature(s) {11,5,12,3} accuracy is 0.77%
	Removing feature(s) {11,5,12,4} accuracy is 0.79%
	Removing feature(s) {11,5,12,6} accuracy is 0.656%
	Removing feature(s) {11,5,12,7} accuracy is 0.784%
	Removing feature(s) {11,5,12,8} accuracy is 0.79%
	Removing feature(s) {11,5,12,9} accuracy is 0.722%
	Removing feature(s) {11,5,12,10} accuracy is 0.788%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {11,5,12,2} was best, accuracy is 0.798%

	Removing feature(s) {11,5,12,2,1} accuracy is 0.814%
	Removing feature(s) {11,5,12,2,3} accuracy is 0.782%
	Removing feature(s) {11,5,12,2,4} accuracy is 0.81%
	Removing feature(s) {11,5,12,2,6} accuracy is 0.698%
	Removing feature(s) {11,5,12,2,7} accuracy is 0.82%
	Removing feature(s) {11,5,12,2,8} accuracy is 0.826%
	Removing feature(s) {11,5,12,2,9} accuracy is 0.742%
	Removing feature(s) {11,5,12,2,10} accuracy is 0.81%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {11,5,12,2,8} was best, accuracy is 0.826%

	Removing feature(s) {11,5,12,2,8,1} accuracy is 0.816%
	Removing feature(s) {11,5,12,2,8,3} accuracy is 0.81%
	Removing feature(s) {11,5,12,2,8,4} accuracy is 0.842%
	Removing feature(s) {11,5,12,2,8,6} accuracy is 0.674%
	Removing feature(s) {11,5,12,2,8,7} accuracy is 0.866%
	Removing feature(s) {11,5,12,2,8,9} accuracy is 0.728%
	Removing feature(s) {11,5,12,2,8,10} accuracy is 0.848%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {11,5,12,2,8,7} was best, accuracy is 0.866%

	Removing feature(s) {11,5,12,2,8,7,1} accuracy is 0.846%
	Removing feature(s) {11,5,12,2,8,7,3} accuracy is 0.814%
	Removing feature(s) {11,5,12,2,8,7,4} accuracy is 0.862%
	Removing feature(s) {11,5,12,2,8,7,6} accuracy is 0.696%
	Removing feature(s) {11,5,12,2,8,7,9} accuracy is 0.76%
	Removing feature(s) {11,5,12,2,8,7,10} accuracy is 0.866%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {11,5,12,2,8,7,10} was best, accuracy is 0.866%

	Removing feature(s) {11,5,12,2,8,7,10,1} accuracy is 0.89%
	Removing feature(s) {11,5,12,2,8,7,10,3} accuracy is 0.892%
	Removing feature(s) {11,5,12,2,8,7,10,4} accuracy is 0.882%
	Removing feature(s) {11,5,12,2,8,7,10,6} accuracy is 0.73%
	Removing feature(s) {11,5,12,2,8,7,10,9} accuracy is 0.776%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {11,5,12,2,8,7,10,3} was best, accuracy is 0.892%

	Removing feature(s) {11,5,12,2,8,7,10,3,1} accuracy is 0.928%
	Removing feature(s) {11,5,12,2,8,7,10,3,4} accuracy is 0.914%
	Removing feature(s) {11,5,12,2,8,7,10,3,6} accuracy is 0.706%
	Removing feature(s) {11,5,12,2,8,7,10,3,9} accuracy is 0.82%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {11,5,12,2,8,7,10,3,1} was best, accuracy is 0.928%

	Removing feature(s) {11,5,12,2,8,7,10,3,1,4} accuracy is 0.95%
	Removing feature(s) {11,5,12,2,8,7,10,3,1,6} accuracy is 0.74%
	Removing feature(s) {11,5,12,2,8,7,10,3,1,9} accuracy is 0.822%

Feature set {11,5,12,2,8,7,10,3,1,4} was best, accuracy is 0.95%

	Removing feature(s) {11,5,12,2,8,7,10,3,1,4,6} accuracy is 0.742%
	Removing feature(s) {11,5,12,2,8,7,10,3,1,4,9} accuracy is 0.84%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {11,5,12,2,8,7,10,3,1,4,9} was best, accuracy is 0.84%

	Removing feature(s) {11,5,12,2,8,7,10,3,1,4,9,6} accuracy is 0.214%

(Warning, Accuracy has decreased!!! Continuing search in case of local maxima)

Feature set {11,5,12,2,8,7,10,3,1,4,9,6} was best, accuracy is 0.214%

Finished search!!! The best feature subset is {6,9}, which has an accuracy of 0.95%
Elapsed (after compilation) = 92.38901543617249
