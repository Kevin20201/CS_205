{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries Used\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/jnsrc7z51m96yrq49msyk2rh0000gn/T/ipykernel_13204/3497228385.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  small_data_19 = pd.read_csv('/Users/kevintu/Documents/Python/CS205/CS_205/CS205_small_Data__19.txt', sep='  ', header=None)\n",
      "/var/folders/6j/jnsrc7z51m96yrq49msyk2rh0000gn/T/ipykernel_13204/3497228385.py:9: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  large_data_6 = pd.read_csv('/Users/kevintu/Documents/Python/CS205/CS_205/CS205_large_Data__6.txt', sep='  ', header=None)\n"
     ]
    }
   ],
   "source": [
    "### Referenced GeeksforGeeks to read in a txt file https://www.geeksforgeeks.org/how-to-read-space-delimited-files-in-pandas/#\n",
    "small_data_19 = pd.read_csv('/Users/kevintu/Documents/Python/CS205/CS_205/CS205_small_Data__19.txt', sep='  ', header=None)\n",
    "### Referenced pandas library documentation for renaming a column https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html\n",
    "small_data_19 = small_data_19.rename(columns={0 : \"label\"})\n",
    "# print(small_data_19)\n",
    "# print(small_data_19.head(5))\n",
    "\n",
    "### Referenced GeeksforGeeks to read in a txt file https://www.geeksforgeeks.org/how-to-read-space-delimited-files-in-pandas/#\n",
    "large_data_6 = pd.read_csv('/Users/kevintu/Documents/Python/CS205/CS_205/CS205_large_Data__6.txt', sep='  ', header=None)\n",
    "### Referenced pandas library documentation for renaming a column https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html\n",
    "large_data_6 = large_data_6.rename(columns={0 : \"label\"})\n",
    "# print(large_data_6)\n",
    "# print(large_data_6.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_Classifier:\n",
    "    def __init__(self, train_set=None, test_set=None, k=None, nearest_neighbors=None):\n",
    "        self.train_set = train_set\n",
    "        self.test_set = test_set\n",
    "        self.k = k\n",
    "        self.nearest_neightbors = nearest_neighbors\n",
    "\n",
    "    def distance(self, nums):\n",
    "        sum = 0\n",
    "        for num in nums:\n",
    "            sum += num**2\n",
    "        return np.sqrt(sum)\n",
    "        \n",
    "    def pred_class(self):\n",
    "        pred_classes = []\n",
    "        for row in range(self.k):\n",
    "            # print(\"KNN: \", self.train_set[self.nearest_neighbors[row]])\n",
    "            # print(\"KNN: \", self.train_set[self.nearest_neighbors[row]][0])\n",
    "            pred_classes.append(self.train_set[self.nearest_neighbors[row]][0])\n",
    "        ### Referenced NumPy unique to return the predicted class https://numpy.org/doc/stable/reference/generated/numpy.unique.html\n",
    "        classes, counts = np.unique(pred_classes, return_counts=True)\n",
    "        if len(counts) == 1:\n",
    "            return classes\n",
    "        if counts[0] > counts[1]:\n",
    "            return classes[0]\n",
    "        return classes[1]\n",
    "    \n",
    "    def train(self):\n",
    "        ### Test every testing entry to training entry\n",
    "        nearest_neighbors = []\n",
    "        # print(self.test_set)\n",
    "        for train_row in self.train_set:\n",
    "            # print(train_row)\n",
    "            # for test_row in self.test_set:\n",
    "            #     print(test_row)\n",
    "            nearest_neighbors.append(self.distance(train_row[1:] - self.test_set[1:]))\n",
    "        # print(nearest_neighbors)\n",
    "        ### Referenced NumPy argsort to sort by index of distances https://numpy.org/doc/stable/reference/generated/numpy.argsort.html\n",
    "        self.nearest_neighbors = np.argsort(nearest_neighbors)\n",
    "        # print(self.nearest_neighbors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  feature_1  feature_2\n",
      "0      2          1          2\n",
      "1      1         11         12\n",
      "2      1         10         11\n",
      "3      2          1          2\n",
      "   label  feature_1  feature_2\n",
      "0      2          1          2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,) (0,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[613], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_data)\n\u001b[1;32m     17\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNN_Classifier(train_data\u001b[38;5;241m.\u001b[39mto_numpy(), test_data\u001b[38;5;241m.\u001b[39mto_numpy(), \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(knn\u001b[38;5;241m.\u001b[39mpred_class())\n",
      "Cell \u001b[0;32mIn[612], line 36\u001b[0m, in \u001b[0;36mKNN_Classifier.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# print(self.test_set)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# print(train_row)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# for test_row in self.test_set:\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m#     print(test_row)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     nearest_neighbors\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistance(\u001b[43mtrain_row\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m))\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# print(nearest_neighbors)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m### Referenced NumPy argsort to sort by index of distances https://numpy.org/doc/stable/reference/generated/numpy.argsort.html\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnearest_neighbors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(nearest_neighbors)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,) (0,3) "
     ]
    }
   ],
   "source": [
    "### Start by splitting my data into train and test set\n",
    "data = {'label': [2.0000000e+000, 1.0000000e+000, 2.0000000e+000, 1.0000000e+000, 2],\n",
    "        'feature_1': [1.2340000e+010, 6.0668000e+000, 2.3400000e+010, 4.5645400e+010, 1],\n",
    "        'feature_2': [ 2.3440000e+000, 5.0770000e+000, 3.6460000e+000, 3.0045000e+000, 2]}\n",
    "data = {'label': [2, 1, 2, 1, 2],\n",
    "        'feature_1': [1, 10, 2, 11, 1],\n",
    "        'feature_2': [ 2, 11, 3, 12, 2]}\n",
    "df = pd.DataFrame(data)\n",
    "# print(df)\n",
    "train_data = df.sample(frac = 0.8, random_state = 4)\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "print(train_data)\n",
    "test_data = df.drop(train_data.index)\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "print(test_data)\n",
    "\n",
    "knn = KNN_Classifier(train_data.to_numpy(), test_data.to_numpy(), 3)\n",
    "knn.train()\n",
    "print(knn.pred_class())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Selection:\n",
    "    def __init__(self, dataset=None, k=None, feature_set=None):\n",
    "        self.dataset=dataset\n",
    "        self.k=k\n",
    "        self.feature_set = []\n",
    "        self.feature_subset = pd.DataFrame(dataset['label'])\n",
    "    \n",
    "    def print_feature_set(self):\n",
    "        print(self.feature_set)\n",
    "        \n",
    "    def populate_feature_subset(self):\n",
    "        self.feature_subset = copy.deepcopy(self.dataset)\n",
    "        \n",
    "    def greedy_forward(self):\n",
    "        # self.feature_subset = pd.concat([self.feature_subset, pd.DataFrame(self.dataset[6])], axis=1)\n",
    "        # self.feature_subset = pd.concat([self.feature_subset, pd.DataFrame(self.dataset[11])], axis=1)\n",
    "        # self.feature_subset = pd.concat([self.feature_subset, pd.DataFrame(self.dataset[9])], axis=1)\n",
    "        if self.dataset.shape[1] == 1:\n",
    "            return\n",
    "        precision = []\n",
    "        feature_name = []\n",
    "        ### Retreiving the Columns for Feature Selection\n",
    "        for column in self.dataset.columns:\n",
    "            if column == 'label':\n",
    "                continue\n",
    "            # print(column)\n",
    "            feature = pd.concat([self.feature_subset, pd.DataFrame(self.dataset[column])], axis=1).to_numpy()\n",
    "            # print(feature)\n",
    "            correct = 0\n",
    "            ### K-Fold CV\n",
    "            for cfv in range(int(len(feature)/self.k)):\n",
    "                # print(cfv)\n",
    "                # print(len(feature)/self.k)\n",
    "                train_data = np.delete(feature, cfv, axis=0)\n",
    "                # print(train_data)\n",
    "                test_data = feature[cfv]\n",
    "                # print(test_data)\n",
    "\n",
    "                knn = KNN_Classifier(train_data, test_data, 1)\n",
    "                knn.train()\n",
    "                # print(test_data[0])\n",
    "                # print(knn.pred_class()[0])\n",
    "                if knn.pred_class()[0] == test_data[0]:\n",
    "                    # print('HELLO')\n",
    "                    correct += 1\n",
    "            precision.append(correct/int(len(feature)/self.k))\n",
    "            feature_name.append(column)\n",
    "        # print(precision)\n",
    "        # print(feature_name)\n",
    "        precision_index = np.argsort(precision)\n",
    "        # print(precision_index)\n",
    "        # print(\"Best feature performed with: \", precision[precision_index[-1]])\n",
    "        # print(\"Best feature performed is feature: \", feature_name[precision_index[-1]])\n",
    "        # print(\"Selected feature is: \",self.dataset.columns[precision_index[-1]]+1)\n",
    "        # print(\"Selected feature is: \",feature_name[precision_index[-1]])\n",
    "        self.feature_set.append(feature_name[precision_index[-1]])\n",
    "        print(precision[precision_index[-1]])\n",
    "        print(self.feature_set)\n",
    "        ### Referenced Pandas library to understand how to drop column https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html\n",
    "        self.feature_subset = pd.concat([self.feature_subset, pd.DataFrame(self.dataset[feature_name[precision_index[-1]]])], axis=1)\n",
    "        # print(self.feature_subset)\n",
    "        self.dataset = self.dataset.drop(columns=[feature_name[precision_index[-1]]])\n",
    "        # print(self.dataset)\n",
    "        self.greedy_forward()\n",
    "        self.print_feature_set\n",
    "        pass\n",
    "    \n",
    "    def greedy_backward(self):\n",
    "        if self.feature_subset.shape[1] == 1:\n",
    "            return\n",
    "        precision = []\n",
    "        feature_name = []\n",
    "        ### Retreiving the Columns for Feature Selection\n",
    "        for column in self.dataset.columns:\n",
    "            if column == 'label':\n",
    "                continue\n",
    "            # print(column)\n",
    "            feature = self.feature_subset.drop(columns=[column]).to_numpy()\n",
    "            # print(feature)\n",
    "            correct = 0\n",
    "            ### K-Fold CV\n",
    "            for cfv in range(int(len(feature)/self.k)):\n",
    "                # print(cfv)\n",
    "                # print(len(feature)/self.k)\n",
    "                train_data = np.delete(feature, cfv, axis=0)\n",
    "                # print(train_data)\n",
    "                test_data = feature[cfv]\n",
    "                # print(test_data)\n",
    "\n",
    "                knn = KNN_Classifier(train_data, test_data, 1)\n",
    "                knn.train()\n",
    "                # print(test_data[0])\n",
    "                # print(knn.pred_class()[0])\n",
    "                if knn.pred_class()[0] == test_data[0]:\n",
    "                    # print('HELLO')\n",
    "                    correct += 1\n",
    "            precision.append(correct/int(len(feature)/self.k))\n",
    "            feature_name.append(column)\n",
    "        # print(precision)\n",
    "        # print(feature_name)\n",
    "        precision_index = np.argsort(precision)\n",
    "        # print(precision_index)\n",
    "        # print(\"Best feature performed with: \", precision[precision_index[-1]])\n",
    "        # print(\"Best feature performed is feature: \", feature_name[precision_index[-1]])\n",
    "        # print(\"Selected feature is: \",self.dataset.columns[precision_index[-1]]+1)\n",
    "        # print(\"Selected feature is: \",feature_name[precision_index[-1]])\n",
    "        print(precision[precision_index[-1]])\n",
    "        self.feature_set.append(feature_name[precision_index[-1]])\n",
    "        print(self.feature_set)\n",
    "        ### Referenced Pandas library to understand how to drop column https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html\n",
    "        self.feature_subset = self.feature_subset.drop(columns=[feature_name[precision_index[-1]]])\n",
    "        # print(self.feature_subset)\n",
    "        self.dataset = self.dataset.drop(columns=[feature_name[precision_index[-1]]])\n",
    "        # print(self.dataset)\n",
    "        self.greedy_backward()\n",
    "        self.print_feature_set\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.758\n",
      "[11]\n",
      "0.784\n",
      "[11, 5]\n",
      "0.784\n",
      "[11, 5, 12]\n",
      "0.798\n",
      "[11, 5, 12, 2]\n",
      "0.826\n",
      "[11, 5, 12, 2, 8]\n",
      "0.866\n",
      "[11, 5, 12, 2, 8, 7]\n",
      "0.866\n",
      "[11, 5, 12, 2, 8, 7, 10]\n",
      "0.892\n",
      "[11, 5, 12, 2, 8, 7, 10, 3]\n",
      "0.928\n",
      "[11, 5, 12, 2, 8, 7, 10, 3, 1]\n",
      "0.95\n",
      "[11, 5, 12, 2, 8, 7, 10, 3, 1, 4]\n",
      "0.84\n",
      "[11, 5, 12, 2, 8, 7, 10, 3, 1, 4, 9]\n",
      "0.214\n",
      "[11, 5, 12, 2, 8, 7, 10, 3, 1, 4, 9, 6]\n"
     ]
    }
   ],
   "source": [
    "### Start by splitting my data into train and test set\n",
    "data = {'label': [2, 1, 2, 1, 2],\n",
    "        'feature_1': [1, 10, 2, 11, 1],\n",
    "        'feature_2': [ 2, 11, 3, 12, 2],\n",
    "        'feature_3': [ 15, 15, 15, 15, 15],}\n",
    "df = pd.DataFrame(data)\n",
    "# print(df)\n",
    "# df = small_data_19.head(5)\n",
    "df = small_data_19\n",
    "# df = large_data_6\n",
    "train_data = df.sample(frac = 0.8, random_state = 4)\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "# print(train_data)\n",
    "test_data = df.drop(train_data.index)\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "# print(test_data)\n",
    "\n",
    "# feat_select = Feature_Selection(train_data, 1)\n",
    "feat_select = Feature_Selection(df, 1)\n",
    "feat_select.greedy_forward()\n",
    "feat_select.populate_feature_subset()\n",
    "feat_select.greedy_backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
